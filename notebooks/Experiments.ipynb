{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor as T\n",
    "\n",
    "from src.agent import Agent\n",
    "from src.utils import TrajStats, set_seeds, arr2var\n",
    "from src.envs_wrappers import SubprocEnvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_kl(logits_1, logits_2):\n",
    "    \"\"\"\n",
    "    Computes KL divergence between discrete distributions\n",
    "    \"\"\"\n",
    "    probs_1 = F.softmax(logits_1, dim=-1)\n",
    "    kl_components = probs_1 * (F.log_softmax(logits_1, dim=-1) - F.log_softmax(logits_2, dim=-1))\n",
    "    return torch.mean(torch.sum(kl_components, dim=1))\n",
    "\n",
    "\n",
    "def get_flat_params(model):\n",
    "    return torch.cat([param.data.view(-1) for param in model.parameters()])\n",
    "\n",
    "\n",
    "def set_flat_params(model, flat_params):\n",
    "    ind_start = 0\n",
    "    for param in model.parameters():\n",
    "        ind_end = ind_start + np.prod(param.shape)\n",
    "        param.data.copy_(flat_params[ind_start : ind_end].view(param.shape))\n",
    "        ind_start = ind_end\n",
    "        \n",
    "def set_flat_grads(model, flat_grads):\n",
    "    ind_start = 0\n",
    "    for param in model.parameters():\n",
    "        ind_end = ind_start + np.prod(param.shape)\n",
    "        param.grad = flat_grads[ind_start : ind_end].view(param.shape)\n",
    "        ind_start = ind_end\n",
    "        \n",
    "def get_flat_grads(model, loss, support_next_order=False):\n",
    "    \"\"\"\n",
    "    Walkaround for computing grads in case loss does not depend on some leafs\n",
    "    TODO: remove `try` later\n",
    "    \"\"\"\n",
    "    \n",
    "    if support_next_order:\n",
    "        grads = []\n",
    "        for param in model.parameters():\n",
    "            try:\n",
    "                grads.append(torch.autograd.grad(loss, param, create_graph=True)[0])\n",
    "            except RuntimeError:\n",
    "                grads.append(Variable(torch.zeros_like(param.data)))\n",
    "    else:\n",
    "        for p in model.parameters():\n",
    "            p.grad = None\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        grads = [p.grad if p.grad is not None else Variable(torch.zeros_like(p.data))\n",
    "                 for p in model.parameters()]\n",
    "        \n",
    "    return torch.cat([grad.view(-1) for grad in grads])\n",
    "        \n",
    "def cg(matvec, b, cg_iters=10, residual_tol=1e-10):\n",
    "    \"\"\"\n",
    "    Solves system Ax=b via conjugate gradients method.\n",
    "    Adapted from John Schulman's code:\n",
    "    https://github.com/joschu/modular_rl/blob/master/modular_rl/trpo.py\n",
    "    Arguments:\n",
    "        matvec        --  matrix-vector product function\n",
    "        b             --  right-hand side\n",
    "        cg_iters      --  number of iterations\n",
    "        residual_tol  --  tolerance\n",
    "    \"\"\"\n",
    "    \n",
    "    x = torch.zeros(b.size())\n",
    "    r = b.clone()\n",
    "    p = b.clone()\n",
    "    rdotr = torch.dot(r, r)\n",
    "    \n",
    "    for i in range(cg_iters):\n",
    "        Ap = matvec(p)\n",
    "        alpha = rdotr / torch.dot(p, Ap)\n",
    "        x += alpha * p\n",
    "        r -= alpha * Ap\n",
    "        newrdotr = torch.dot(r, r)\n",
    "        beta = newrdotr / rdotr\n",
    "        p = r + beta * p\n",
    "        rdotr = newrdotr\n",
    "        if rdotr < residual_tol:\n",
    "            break\n",
    "            \n",
    "    return x\n",
    "\n",
    "def linesearch(f, x, fullstep, expected_improve_rate, max_backtracks=10, accept_ratio=.05):\n",
    "    \"\"\"\n",
    "    Backtracking linesearch for finding optimal proposed step size.\n",
    "    Adapted from John Schulman's code:\n",
    "    https://github.com/joschu/modular_rl/blob/master/modular_rl/trpo.py\n",
    "    Arguments:\n",
    "        f                      --  \n",
    "        x                      --  \n",
    "        fullstep               --  \n",
    "        expected_improve_rate  --  \n",
    "        max_backtracks         --\n",
    "        accept_ratio           --\n",
    "    \"\"\"\n",
    "    fval = f(x)\n",
    "    x_best = None\n",
    "    max_ratio = -1\n",
    "    for stepfrac in .5**np.arange(max_backtracks):\n",
    "        xnew = x + stepfrac*fullstep\n",
    "        newfval = f(xnew)\n",
    "        actual_improve = (newfval - fval).data[0]\n",
    "        if actual_improve > 0:\n",
    "            expected_improve = expected_improve_rate * stepfrac\n",
    "            ratio = actual_improve / expected_improve\n",
    "            if ratio > accept_ratio and ratio > max_ratio:\n",
    "                max_ratio = ratio\n",
    "                x_best = xnew\n",
    "        \n",
    "    return (True, x_best) if x_best is not None else (False, x) \n",
    "\n",
    "\n",
    "def hess_vec_full(vec, model, grads, damping):\n",
    "    grads_vec = torch.dot(grads, Variable(vec))\n",
    "    res = get_flat_grads(model, grads_vec).data\n",
    "\n",
    "    return res + damping * vec\n",
    "\n",
    "\n",
    "def compute_obj_full(flat_params, agent, tss, gamma, lambda_gae):\n",
    "    # TODO: rewrite without new TrajStats \n",
    "    # TODO: and probably rewrite TrajStats, e.g. append to dict, make calc_gae not a method of class\n",
    "    \n",
    "    set_flat_params(agent, flat_params)\n",
    "    \n",
    "    res = 0\n",
    "    \n",
    "    for ts in tss:\n",
    "        cur_ts = TrajStats()\n",
    "        cur_ts.rewards = ts.rewards\n",
    "        cur_ts.states = ts.states\n",
    "        cur_ts.actions = ts.actions\n",
    "        \n",
    "        cur_ts.logits, cur_ts.values = agent.forward(cur_ts.states)\n",
    "        cur_ts.values = [v for v in cur_ts.values]\n",
    "        cur_ts.logs_pi_a = F.log_softmax(cur_ts.logits, dim=-1)[np.arange(len(cur_ts.actions)), \n",
    "                                                                np.array(cur_ts.actions)]\n",
    "        cur_ts.logs_pi_a = [l for l in cur_ts.logs_pi_a]\n",
    "        \n",
    "        advantages = cur_ts.calc_gaes(gamma, lambda_gae)\n",
    "        #advantages = cur_ts.calc_advs(gamma, n_step=1)\n",
    "        old_logs_pi = ts.get_logs_pi_a()\n",
    "        logs_pi = cur_ts.get_logs_pi_a()\n",
    "        res += (torch.exp(logs_pi - old_logs_pi) * advantages.detach()).sum()\n",
    "    \n",
    "    return res / len(tss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def check_vol():\n",
    "    return len(list(filter(lambda x: x.volatile, list(agent.parameters())))) == 0\n",
    "\n",
    "def get_flat_grads_without_try(model, loss):\n",
    "    \"\"\"\n",
    "    temporary, remove it later\n",
    "    \"\"\"\n",
    "    \n",
    "    grads = []\n",
    "    for name, param in model.named_parameters():\n",
    "        grads.append(torch.autograd.grad(loss, param, create_graph=True)[0])\n",
    "            \n",
    "    return torch.cat([grad.view(-1) for grad in grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg_damping = 1e-3\n",
    "max_kl = 1e-2\n",
    "global crl\n",
    "global entr_l\n",
    "global acl \n",
    "global returns_l\n",
    "crl = []\n",
    "entr_l = []\n",
    "acl = []\n",
    "returns_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn(agent, envs, update_rule, n_timesteps=1e5, gamma=0.99, lambda_gae=0.99, entr_coef=1e-3, log_interval=1e4):\n",
    "    \"\"\"\n",
    "    Optimize networks parameters via interacting with env\n",
    "    Arguments:\n",
    "        agent           --  agent to optimize\n",
    "        envs            --  list of environments to interact with\n",
    "        update_rule     --  'A2C', 'TRPO' or 'K-FAC', str\n",
    "        n_timesteps     --  number of interactions with environments, int\n",
    "        lambda_gae      --  mixing coefficient in generalized advantage estimation\n",
    "        entr_coef       --  entropy loss multiplier, float\n",
    "        log_interval    --  number of timesteps to print debug info, int\n",
    "    \"\"\"\n",
    "    ENTR_C = 0#1e1\n",
    "    global returns_l\n",
    "    returns_l = []\n",
    "    \n",
    "    n_envs = len(envs)\n",
    "    w_envs = SubprocEnvs(envs)\n",
    "\n",
    "    agent.train()\n",
    "    returns = []\n",
    "    timestep = 0\n",
    "    timestep_diff = 0\n",
    "    \n",
    "    if update_rule == 'A2C':\n",
    "        optimizer = optim.Adam(agent.parameters(), lr=1e-3)\n",
    "    elif update_rule == 'TRPO':\n",
    "        optimizer = optim.Adam(agent.net.value_head.parameters())\n",
    "    elif update_tule == 'K-FAC':\n",
    "        raise NotImplementedError\n",
    "        optimizer = KFACOptimizer(agent.parameters())\n",
    "    else:\n",
    "        raise ValueError('Unknown update rule')\n",
    "\n",
    "    while timestep < n_timesteps:\n",
    "        states = w_envs.reset()\n",
    "        tss = [TrajStats() for _ in range(n_envs)]\n",
    "\n",
    "        while w_envs.has_alive_envs():\n",
    "            logits, value = agent.forward(states)\n",
    "            actions = agent.sample_action(logits)\n",
    "\n",
    "            ind_alive = w_envs.get_indices_alive()\n",
    "            states_new, rewards, done, _ = w_envs.step(actions)      \n",
    "            \n",
    "            for i, i_alive in enumerate(ind_alive):\n",
    "                tss[i_alive].append(rewards[i], F.log_softmax(logits[i], dim=-1)[actions[i]], value[i], logits[i], states[i], actions[i])\n",
    "            states = states_new[np.logical_not(done)]\n",
    "\n",
    "            timestep_diff += len(ind_alive)\n",
    "            timestep += len(ind_alive)\n",
    "            if timestep_diff >= log_interval:\n",
    "                ENTR_C *= 0.75\n",
    "                timestep_diff -= log_interval\n",
    "                print('{} timesteps, av. return: {:.3f}'.format((timestep // log_interval) * log_interval, \n",
    "                                                                np.mean(returns[-300:])))\n",
    "        critic_loss = 0\n",
    "        actor_loss = 0\n",
    "        entr = 0\n",
    "        for ts in tss:\n",
    "            episode_returns = ts.calc_episode_returns(gamma)\n",
    "            critic_loss += 0.5*(ts.get_values() - episode_returns).pow(2).sum()\n",
    "            returns.append(ts.calc_return(gamma))\n",
    "            returns_l.append(returns[-1])\n",
    "            \n",
    "            advantages = ts.calc_gaes(gamma, lambda_gae)\n",
    "            logs_pi = ts.get_logs_pi_a()\n",
    "            \n",
    "            logits = ts.get_logits()\n",
    "            p = F.softmax(logits, dim=1)\n",
    "            entr += -(p * torch.log(p)).sum()\n",
    "            #entr += -(logs_pi * torch.exp(logs_pi)).sum()\n",
    "            \n",
    "            actor_loss += -(logs_pi * advantages.detach()).sum()  # minus added in order to ascend\n",
    "\n",
    "        global crl\n",
    "        global entr_l\n",
    "        global acl \n",
    "        crl.append(critic_loss.data[0])\n",
    "        entr_l.append(entr.data[0])\n",
    "        acl.append(actor_loss.data[0])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if update_rule == 'A2C' or update_rule == 'K-FAC':\n",
    "            #print (actor_loss, critic_loss, entr)\n",
    "            ((actor_loss + critic_loss - ENTR_C * entr) / n_envs).backward()\n",
    "            optimizer.step()\n",
    "        elif update_rule == 'TRPO':\n",
    "            \n",
    "            critic_flat_grads = get_flat_grads(agent, critic_loss/n_envs)\n",
    "            flat_grads = get_flat_grads(agent, (actor_loss - ENTR_C * entr) ).data\n",
    "            \n",
    "            if np.allclose(flat_grads.numpy(), 0):\n",
    "                print('zero gradients, passing')\n",
    "                continue\n",
    "\n",
    "            kl = 0\n",
    "            for ts in tss:\n",
    "                logits = ts.get_logits()\n",
    "                kl += compute_kl(logits, logits.detach())\n",
    "\n",
    "            flat_grads_kl = get_flat_grads(agent, kl, support_next_order=True)\n",
    "            hess_vec = lambda vec: hess_vec_full(vec, agent, flat_grads_kl, cg_damping)\n",
    "\n",
    "            stepdir = cg(hess_vec, -flat_grads, cg_iters=10)\n",
    "            shs = 0.5 * torch.dot(stepdir, hess_vec(stepdir))\n",
    "            \n",
    "            lm = np.sqrt(shs / max_kl)\n",
    "            proposed_step = stepdir / lm\n",
    "            neggdotstepdir = torch.dot(-flat_grads, stepdir)\n",
    "\n",
    "            compute_obj = lambda flat_params: compute_obj_full(flat_params, agent, tss, gamma, lambda_gae)\n",
    "            params_prev = get_flat_params(agent)\n",
    "            success, params_new = linesearch(compute_obj, params_prev, proposed_step, neggdotstepdir / lm)\n",
    "            set_flat_params(agent, params_new)\n",
    "\n",
    "            set_flat_grads(agent, critic_flat_grads)\n",
    "            optimizer.step()\n",
    "        \n",
    "    w_envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ykemaev/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:115: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/ykemaev/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:109: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c32f828f54cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m learn(agent, envs, update_rule, n_timesteps=n_timesteps, gamma=gamma, \n\u001b[0;32m---> 16\u001b[0;31m       lambda_gae=lambda_gae, log_interval=log_interval)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-9a276e11e1b9>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(agent, envs, update_rule, n_timesteps, gamma, lambda_gae, entr_coef, log_interval)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mhess_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhess_vec_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_grads_kl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcg_damping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mstepdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mflat_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcg_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mshs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8584061d72f2>\u001b[0m in \u001b[0;36mcg\u001b[0;34m(matvec, b, cg_iters, residual_tol)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcg_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mAp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdotr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "n_timesteps = 200000\n",
    "gamma = 0.99\n",
    "log_interval = 5000\n",
    "batch_size = 1\n",
    "lambda_gae = 0.99\n",
    "\n",
    "#env = 'CartPole-v1'\n",
    "env = 'FrozenLake-v0'\n",
    "envs = [gym.make(env) for _ in range(batch_size)]\n",
    "set_seeds(envs, 0, False)\n",
    "\n",
    "agent = Agent(envs[0].observation_space, envs[0].action_space)\n",
    "update_rule = 'TRPO'\n",
    "\n",
    "learn(agent, envs, update_rule, n_timesteps=n_timesteps, gamma=gamma, \n",
    "      lambda_gae=lambda_gae, log_interval=log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x120293d68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkwQREVn6f0gcJb4edlHDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12041c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "window_size = 50\n",
    "#plt.plot(np.convolve(returns_l, np.ones(window_size) / window_size, mode='valid'))\n",
    "#plt.plot(crl[::2], label='critic')\n",
    "#plt.plot(entr_l[::2], label='entropy')\n",
    "plt.plot(acl[::2], label='actor loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            # TEST\n",
    "            if False:\n",
    "                for p in agent.parameters():\n",
    "                    p.grad = None\n",
    "                actor_loss.backward()\n",
    "                grads = torch.cat([ \n",
    "                    p.grad.data.view(-1) \n",
    "                    for p in agent.parameters() if p.grad is not None\n",
    "                ])\n",
    "                \n",
    "                print (grads.size())\n",
    "                print (flat_grads.size())\n",
    "                print (grads)\n",
    "                print (flat_grads)\n",
    "                return -1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
